{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":50160,"databundleVersionId":7921029,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings\n\nimport statsmodels.api as sm\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import PolynomialFeatures\n\npd.set_option('display.max_columns', None)\n#pd.set_option('display.max_rows', None)\n#pd.options.display.float_format = '{:.2f}'.format\ndef ignore_warn(*args, **kwargs):\n    pass\nwarnings.warn = ignore_warn","metadata":{"execution":{"iopub.status.busy":"2024-05-07T18:07:22.343252Z","iopub.execute_input":"2024-05-07T18:07:22.343651Z","iopub.status.idle":"2024-05-07T18:07:26.151632Z","shell.execute_reply.started":"2024-05-07T18:07:22.343620Z","shell.execute_reply":"2024-05-07T18:07:26.150442Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def preprocess_data(data, features, imputer):\n    data[features] = imputer.transform(data[features])\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-05-07T18:07:26.153763Z","iopub.execute_input":"2024-05-07T18:07:26.154356Z","iopub.status.idle":"2024-05-07T18:07:26.160070Z","shell.execute_reply.started":"2024-05-07T18:07:26.154319Z","shell.execute_reply":"2024-05-07T18:07:26.159018Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def train_model_statsmodels(X, y):\n    X = sm.add_constant(X)\n    model = sm.OLS(y, X).fit(cov_type='HC0')\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-05-07T18:07:26.161338Z","iopub.execute_input":"2024-05-07T18:07:26.163014Z","iopub.status.idle":"2024-05-07T18:07:26.181911Z","shell.execute_reply.started":"2024-05-07T18:07:26.162976Z","shell.execute_reply":"2024-05-07T18:07:26.180608Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def create_k_folds(df, fold_n=5):\n    folds = {}\n    fold_size = len(df) // fold_n\n    for i in range(fold_n):\n        start = i * fold_size\n        if i == fold_n - 1:  # In the last fold, include all remaining data\n            end = len(df)\n        else:\n            end = start + fold_size\n        folds[i] = df[start:end]\n    return folds","metadata":{"execution":{"iopub.status.busy":"2024-05-07T18:07:26.184964Z","iopub.execute_input":"2024-05-07T18:07:26.185948Z","iopub.status.idle":"2024-05-07T18:07:26.193592Z","shell.execute_reply.started":"2024-05-07T18:07:26.185910Z","shell.execute_reply":"2024-05-07T18:07:26.192428Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def find_index(lst, target):\n    for i, number in enumerate(lst):\n        if number == target:\n            return i\n    return None","metadata":{"execution":{"iopub.status.busy":"2024-05-07T18:07:26.194832Z","iopub.execute_input":"2024-05-07T18:07:26.195220Z","iopub.status.idle":"2024-05-07T18:07:26.205697Z","shell.execute_reply.started":"2024-05-07T18:07:26.195185Z","shell.execute_reply":"2024-05-07T18:07:26.204424Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def train_final_model(folds_X, folds_y):\n    cv_amount = len(folds_X)\n    models, rmse_scores, predictions = {}, {}, {}\n    rmse_total = 0\n    \n    for i in range(cv_amount):\n        test_X, test_y = folds_X[i], folds_y[i]\n        train_X = np.concatenate([folds_X[n] for n in range(len(folds_X)) if n != i])\n        train_y = np.concatenate([folds_y[n] for n in range(len(folds_y)) if n != i])\n\n        models['model_{}'.format(i)] = train_model_statsmodels(train_X, train_y)\n        test_X = sm.add_constant(test_X, has_constant='add')\n        y_pred = models['model_{}'.format(i)].predict(test_X)\n        predictions[i] = y_pred\n        \n        rmse_scores[i] = mean_squared_error(np.log1p(test_y), np.log1p(y_pred), squared=False)\n        rmse_total += rmse_scores[i]\n\n    # Final model and the final model's score\n    rmse_average = rmse_total / cv_amount\n    rmse_list = []\n    for i in range(len(rmse_scores)):\n        rmse_list.append(rmse_scores[i])\n    max_rmse = max(rmse_list)\n    min_rmse = min(rmse_list)\n    index_max_rmse = find_index(rmse_list, max_rmse)\n    index_min_rmse = find_index(rmse_list, min_rmse)\n    final_model = models['model_{}'.format(index_max_rmse)]\n    display(final_model.summary())\n    \n    # Residual analysis\n    #residuals_cv = np.expm1(folds_y[index_min_r2]) - predictions[index_min_r2]\n    #plot_residuals(residuals_cv, predictions[index_min_r2])\n    #normality(residuals_cv)\n    #print(residuals_cv.sort_values())\n    print(\"-----------------------------------------------------------------------------\")\n    print(\"All RMSE score:  \", rmse_scores)\n    print(\"Max RMSE score:  \", rmse_scores[index_max_rmse], index_max_rmse)\n    print(\"Min RMSE score:  \", rmse_scores[index_min_rmse], index_min_rmse)\n    print(\"Average RMSE score:  \", rmse_average)\n    return final_model, rmse_average","metadata":{"execution":{"iopub.status.busy":"2024-05-07T18:07:26.207508Z","iopub.execute_input":"2024-05-07T18:07:26.208166Z","iopub.status.idle":"2024-05-07T18:07:26.222428Z","shell.execute_reply.started":"2024-05-07T18:07:26.208128Z","shell.execute_reply":"2024-05-07T18:07:26.221244Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def cyclic_features(df, df_):\n    df['date_decision'] = pd.to_datetime(df['date_decision'])\n    \n    days_in_year = 365.25\n    df['day_of_year'] = df['date_decision'].dt.dayofyear\n    df['year_sin'] = np.sin(2 * np.pi * df['day_of_year'] / days_in_year)\n    df['year_cos'] = np.cos(2 * np.pi * df['day_of_year'] / days_in_year)\n    \n    days_in_month = 30.437\n    df['day_of_month'] = df['date_decision'].dt.day\n    df['month_sin'] = np.sin(2 * np.pi * df['day_of_month'] / days_in_month)\n    df['month_cos'] = np.cos(2 * np.pi * df['day_of_month'] / days_in_month)\n    \n    days_in_week = 7\n    df['day_of_week'] = df['date_decision'].dt.dayofweek\n    df['week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / days_in_week)\n    df['week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / days_in_week)\n    \n\n    df_['date_decision'] = pd.to_datetime(df_['date_decision'])\n    \n    days_in_year = 365.25\n    df_['day_of_year'] = df_['date_decision'].dt.dayofyear\n    df_['year_sin'] = np.sin(2 * np.pi * df_['day_of_year'] / days_in_year)\n    df_['year_cos'] = np.cos(2 * np.pi * df_['day_of_year'] / days_in_year)\n    \n    days_in_month = 30.437\n    df_['day_of_month'] = df_['date_decision'].dt.day\n    df_['month_sin'] = np.sin(2 * np.pi * df_['day_of_month'] / days_in_month)\n    df_['month_cos'] = np.cos(2 * np.pi * df_['day_of_month'] / days_in_month)\n    \n    days_in_week = 7\n    df_['day_of_week'] = df_['date_decision'].dt.dayofweek\n    df_['week_sin'] = np.sin(2 * np.pi * df_['day_of_week'] / days_in_week)\n    df_['week_cos'] = np.cos(2 * np.pi * df_['day_of_week'] / days_in_week)\n    return df, df_","metadata":{"execution":{"iopub.status.busy":"2024-05-07T18:07:26.223751Z","iopub.execute_input":"2024-05-07T18:07:26.224400Z","iopub.status.idle":"2024-05-07T18:07:26.238344Z","shell.execute_reply.started":"2024-05-07T18:07:26.224351Z","shell.execute_reply":"2024-05-07T18:07:26.237272Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_path = '/kaggle/input/home-credit-credit-risk-model-stability/csv_files/train/train_base.csv'\ntest_path = '/kaggle/input/home-credit-credit-risk-model-stability/csv_files/test/test_base.csv'\n\ntrain = pd.read_csv(train_path)\ntest = pd.read_csv(test_path)\n\ntrain, test = cyclic_features(train, test)\n\nselected_features = ['MONTH', 'WEEK_NUM', 'year_sin', 'year_cos', 'month_sin', 'month_cos', 'week_sin', 'week_cos']","metadata":{"execution":{"iopub.status.busy":"2024-05-07T18:08:03.477735Z","iopub.execute_input":"2024-05-07T18:08:03.478610Z","iopub.status.idle":"2024-05-07T18:08:04.763800Z","shell.execute_reply.started":"2024-05-07T18:08:03.478569Z","shell.execute_reply":"2024-05-07T18:08:04.762701Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"imputer = SimpleImputer(strategy='constant', fill_value=0)\ntrain[selected_features] = imputer.fit_transform(train[selected_features])\n\ntest = preprocess_data(test, selected_features, imputer)\n\ny = train['target']\nX = train[selected_features]\nX_test = test[selected_features]\n\nfolds_X = create_k_folds(X, fold_n=5)\nfolds_y = create_k_folds(y, fold_n=5)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T18:08:06.086672Z","iopub.execute_input":"2024-05-07T18:08:06.087643Z","iopub.status.idle":"2024-05-07T18:08:06.495511Z","shell.execute_reply.started":"2024-05-07T18:08:06.087602Z","shell.execute_reply":"2024-05-07T18:08:06.494441Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"final_model, rmse_average = train_final_model(folds_X, folds_y)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T18:08:08.180319Z","iopub.execute_input":"2024-05-07T18:08:08.181353Z","iopub.status.idle":"2024-05-07T18:08:13.796091Z","shell.execute_reply.started":"2024-05-07T18:08:08.181310Z","shell.execute_reply":"2024-05-07T18:08:13.795032Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.001\nModel:                            OLS   Adj. R-squared:                  0.001\nMethod:                 Least Squares   F-statistic:                     102.7\nDate:                Tue, 07 May 2024   Prob (F-statistic):          4.58e-172\nTime:                        18:08:13   Log-Likelihood:             4.3120e+05\nNo. Observations:             1221328   AIC:                        -8.624e+05\nDf Residuals:                 1221319   BIC:                        -8.623e+05\nDf Model:                           8                                         \nCovariance Type:                  HC0                                         \n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         16.7325      2.279      7.341      0.000      12.265      21.200\nx1         -8.274e-05   1.13e-05     -7.328      0.000      -0.000   -6.06e-05\nx2             0.0002   2.14e-05      8.028      0.000       0.000       0.000\nx3             0.0033      0.000      9.197      0.000       0.003       0.004\nx4             0.0054      0.000     23.564      0.000       0.005       0.006\nx5            -0.0007      0.000     -3.347      0.001      -0.001      -0.000\nx6            -0.0002      0.000     -0.774      0.439      -0.001       0.000\nx7             0.0032      0.000     14.411      0.000       0.003       0.004\nx8            -0.0004      0.000     -1.901      0.057      -0.001    1.27e-05\n==============================================================================\nOmnibus:                  1263783.541   Durbin-Watson:                   1.996\nProb(Omnibus):                  0.000   Jarque-Bera (JB):         47660848.198\nSkew:                           5.524   Prob(JB):                         0.00\nKurtosis:                      31.540   Cond. No.                     2.84e+09\n==============================================================================\n\nNotes:\n[1] Standard Errors are heteroscedasticity robust (HC0)\n[2] The condition number is large, 2.84e+09. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n\"\"\"","text/html":"<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.001</td> \n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.001</td> \n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   102.7</td> \n</tr>\n<tr>\n  <th>Date:</th>             <td>Tue, 07 May 2024</td> <th>  Prob (F-statistic):</th>  <td>4.58e-172</td>\n</tr>\n<tr>\n  <th>Time:</th>                 <td>18:08:13</td>     <th>  Log-Likelihood:    </th> <td>4.3120e+05</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>1221328</td>     <th>  AIC:               </th> <td>-8.624e+05</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>1221319</td>     <th>  BIC:               </th> <td>-8.623e+05</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>      <td> </td>    \n</tr>\n<tr>\n  <th>Covariance Type:</th>         <td>HC0</td>       <th>                     </th>      <td> </td>    \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th> <td>   16.7325</td> <td>    2.279</td> <td>    7.341</td> <td> 0.000</td> <td>   12.265</td> <td>   21.200</td>\n</tr>\n<tr>\n  <th>x1</th>    <td>-8.274e-05</td> <td> 1.13e-05</td> <td>   -7.328</td> <td> 0.000</td> <td>   -0.000</td> <td>-6.06e-05</td>\n</tr>\n<tr>\n  <th>x2</th>    <td>    0.0002</td> <td> 2.14e-05</td> <td>    8.028</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n</tr>\n<tr>\n  <th>x3</th>    <td>    0.0033</td> <td>    0.000</td> <td>    9.197</td> <td> 0.000</td> <td>    0.003</td> <td>    0.004</td>\n</tr>\n<tr>\n  <th>x4</th>    <td>    0.0054</td> <td>    0.000</td> <td>   23.564</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n</tr>\n<tr>\n  <th>x5</th>    <td>   -0.0007</td> <td>    0.000</td> <td>   -3.347</td> <td> 0.001</td> <td>   -0.001</td> <td>   -0.000</td>\n</tr>\n<tr>\n  <th>x6</th>    <td>   -0.0002</td> <td>    0.000</td> <td>   -0.774</td> <td> 0.439</td> <td>   -0.001</td> <td>    0.000</td>\n</tr>\n<tr>\n  <th>x7</th>    <td>    0.0032</td> <td>    0.000</td> <td>   14.411</td> <td> 0.000</td> <td>    0.003</td> <td>    0.004</td>\n</tr>\n<tr>\n  <th>x8</th>    <td>   -0.0004</td> <td>    0.000</td> <td>   -1.901</td> <td> 0.057</td> <td>   -0.001</td> <td> 1.27e-05</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>1263783.541</td> <th>  Durbin-Watson:     </th>   <td>   1.996</td>  \n</tr>\n<tr>\n  <th>Prob(Omnibus):</th>   <td> 0.000</td>    <th>  Jarque-Bera (JB):  </th> <td>47660848.198</td>\n</tr>\n<tr>\n  <th>Skew:</th>            <td> 5.524</td>    <th>  Prob(JB):          </th>   <td>    0.00</td>  \n</tr>\n<tr>\n  <th>Kurtosis:</th>        <td>31.540</td>    <th>  Cond. No.          </th>   <td>2.84e+09</td>  \n</tr>\n</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC0)<br/>[2] The condition number is large, 2.84e+09. This might indicate that there are<br/>strong multicollinearity or other numerical problems.","text/latex":"\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &      0.001    \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &      0.001    \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &      102.7    \\\\\n\\textbf{Date:}             & Tue, 07 May 2024 & \\textbf{  Prob (F-statistic):} &  4.58e-172    \\\\\n\\textbf{Time:}             &     18:08:13     & \\textbf{  Log-Likelihood:    } &  4.3120e+05   \\\\\n\\textbf{No. Observations:} &     1221328      & \\textbf{  AIC:               } &  -8.624e+05   \\\\\n\\textbf{Df Residuals:}     &     1221319      & \\textbf{  BIC:               } &  -8.623e+05   \\\\\n\\textbf{Df Model:}         &           8      & \\textbf{                     } &               \\\\\n\\textbf{Covariance Type:}  &       HC0        & \\textbf{                     } &               \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const} &      16.7325  &        2.279     &     7.341  &         0.000        &       12.265    &       21.200     \\\\\n\\textbf{x1}    &   -8.274e-05  &     1.13e-05     &    -7.328  &         0.000        &       -0.000    &    -6.06e-05     \\\\\n\\textbf{x2}    &       0.0002  &     2.14e-05     &     8.028  &         0.000        &        0.000    &        0.000     \\\\\n\\textbf{x3}    &       0.0033  &        0.000     &     9.197  &         0.000        &        0.003    &        0.004     \\\\\n\\textbf{x4}    &       0.0054  &        0.000     &    23.564  &         0.000        &        0.005    &        0.006     \\\\\n\\textbf{x5}    &      -0.0007  &        0.000     &    -3.347  &         0.001        &       -0.001    &       -0.000     \\\\\n\\textbf{x6}    &      -0.0002  &        0.000     &    -0.774  &         0.439        &       -0.001    &        0.000     \\\\\n\\textbf{x7}    &       0.0032  &        0.000     &    14.411  &         0.000        &        0.003    &        0.004     \\\\\n\\textbf{x8}    &      -0.0004  &        0.000     &    -1.901  &         0.057        &       -0.001    &     1.27e-05     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 1263783.541 & \\textbf{  Durbin-Watson:     } &      1.996    \\\\\n\\textbf{Prob(Omnibus):} &     0.000   & \\textbf{  Jarque-Bera (JB):  } & 47660848.198  \\\\\n\\textbf{Skew:}          &     5.524   & \\textbf{  Prob(JB):          } &       0.00    \\\\\n\\textbf{Kurtosis:}      &    31.540   & \\textbf{  Cond. No.          } &   2.84e+09    \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors are heteroscedasticity robust (HC0) \\newline\n [2] The condition number is large, 2.84e+09. This might indicate that there are \\newline\n strong multicollinearity or other numerical problems."},"metadata":{}},{"name":"stdout","text":"-----------------------------------------------------------------------------\nAll RMSE score:   {0: 0.12304632346915169, 1: 0.11844053209446963, 2: 0.11319893392654351, 3: 0.13259280614825095, 4: 0.1185761993225907}\nMax RMSE score:   0.13259280614825095 3\nMin RMSE score:   0.11319893392654351 2\nAverage RMSE score:   0.12117095899220129\n","output_type":"stream"}]},{"cell_type":"code","source":"model = train_model_statsmodels(X, y)\n\nX = sm.add_constant(X)\ny_pred = model.predict(X)\nrmse_score = mean_squared_error(np.log1p(y), np.log1p(y_pred), squared=False)\nprint(\"RMSE\", rmse_score)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T18:08:13.798122Z","iopub.execute_input":"2024-05-07T18:08:13.798744Z","iopub.status.idle":"2024-05-07T18:08:15.315520Z","shell.execute_reply.started":"2024-05-07T18:08:13.798709Z","shell.execute_reply":"2024-05-07T18:08:15.314423Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"RMSE 0.12125306445809153\n","output_type":"stream"}]},{"cell_type":"code","source":"X_test = sm.add_constant(X_test, has_constant='add')\npredicted_log_score = model.predict(X_test)\npredicted_score = np.expm1(predicted_log_score)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T18:08:15.317161Z","iopub.execute_input":"2024-05-07T18:08:15.317834Z","iopub.status.idle":"2024-05-07T18:08:15.332903Z","shell.execute_reply.started":"2024-05-07T18:08:15.317797Z","shell.execute_reply":"2024-05-07T18:08:15.331756Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"predicted_score_df = pd.DataFrame({\n    'case_id': test['case_id'].to_numpy(),\n    'score': predicted_score\n})\npredicted_score_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T18:08:17.273879Z","iopub.execute_input":"2024-05-07T18:08:17.274715Z","iopub.status.idle":"2024-05-07T18:08:17.282849Z","shell.execute_reply.started":"2024-05-07T18:08:17.274683Z","shell.execute_reply":"2024-05-07T18:08:17.281963Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"predicted_score_df","metadata":{"execution":{"iopub.status.busy":"2024-05-07T18:08:19.025959Z","iopub.execute_input":"2024-05-07T18:08:19.026596Z","iopub.status.idle":"2024-05-07T18:08:19.039441Z","shell.execute_reply.started":"2024-05-07T18:08:19.026565Z","shell.execute_reply":"2024-05-07T18:08:19.038492Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"   case_id     score\n0    57543  0.027669\n1    57549  0.037934\n2    57551  0.034644\n3    57552  0.034644\n4    57569  0.037428\n5    57630  0.038188\n6    57631  0.022142\n7    57632  0.032760\n8    57633  0.040983\n9    57634  0.041975","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>case_id</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>57543</td>\n      <td>0.027669</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>57549</td>\n      <td>0.037934</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>57551</td>\n      <td>0.034644</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>57552</td>\n      <td>0.034644</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57569</td>\n      <td>0.037428</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>57630</td>\n      <td>0.038188</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>57631</td>\n      <td>0.022142</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>57632</td>\n      <td>0.032760</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>57633</td>\n      <td>0.040983</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>57634</td>\n      <td>0.041975</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}